{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Traffic Monitoring and Analysis System - TMAS\n",
    "\n",
    "This notebook is the \"monitoring\" part of TMAS. It has been designed to recognise 4 different classes \n",
    "of vehicle. Each time a vehicle is detected inside the central region of the frame, \n",
    "an entry in a database is made. \n",
    "\n",
    "TMAS has been created by Alexander Tkaczyk-Harrison, for\n",
    "Goldsmtihs, University of London, BSc Creative Computing\n",
    "\n",
    "TMAS uses the YOLO (You Only Look Once) Object Detector, which can be found at:\n",
    "https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "@article{yolov3,\n",
    "  title={YOLOv3: An Incremental Improvement},\n",
    "  author={Redmon, Joseph and Farhadi, Ali},\n",
    "  journal = {arXiv},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "The work of Rajeev Ratan must be noted. This project would not have happened without \n",
    "his excellent course on Udemy (https://www.udemy.com/share/100FTkBUESdFtaQHw=/)\n",
    "\n",
    "The work of GitHub user \"thtrieu\" should also be noted, for converting the original YOLO algorithm\n",
    "to work in Python, with tensorflow: https://github.com/thtrieu/darkflow\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from darkflow.net.build import TFNet # YOLO object detector\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "# create connection and cursor to sqlite database\n",
    "conn = sqlite3.connect('demo.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "\n",
    "# tensorflow config options\n",
    "# prints out which devices your operations and tensors are assigned to (set to True)\n",
    "config = tf.ConfigProto(log_device_placement = False)\n",
    "\n",
    "# GPU growth not needed, \n",
    "# by default Tensorflow maps almost all GPU memory to this process\n",
    "config.gpu_options.allow_growth = False\n",
    "\n",
    "\n",
    "# more tensorflow config options\n",
    "with tf.Session(config = config) as sess:\n",
    "    options = {\n",
    "        'model' : './cfg/tiny-yolo-4c.cfg', # load custom tiny-yolo 4 class model\n",
    "        'load' : 31500,                     # load from checkpoint 31500\n",
    "        'threshold' : 0.5,                  # threshold to return predictions\n",
    "        'gpu' : 1.0                         # GPU ID \n",
    "    }\n",
    "    \n",
    "    # pass these options into the YOLO algorithm\n",
    "    tfnet = TFNet(options) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4 tables (only if they do not exist already), \n",
    "# each table represents each class (cars, vans, HGVs, bikes), \n",
    "# columns are: vehicle type, unix time, 24 hour time, the date, and a value\n",
    "def create_table():\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS cars(vehicle TEXT, unix REAL, hours TEXT, date TEXT, value REAL)')\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS vans(vehicle TEXT, unix REAL, hours TEXT, date TEXT, value REAL)')\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS HGVs(vehicle TEXT, unix REAL, hours TEXT, date TEXT, value REAL)')\n",
    "    c.execute('CREATE TABLE IF NOT EXISTS bikes(vehicle TEXT, unix REAL, hours TEXT, date TEXT, value REAL)')\n",
    "    \n",
    "# define 4 functions, from lines 13, to 42... one for each class of vehicle\n",
    "# when any of the functions are ran, add one to the corresponding table with fields\n",
    "# approriately filled with the vehicles class, and the times and dates of entry\n",
    "def car(date, hours, value, unix):\n",
    "    \n",
    "    # set string to be entered into the first column of the table\n",
    "    vehicle = 'Car'\n",
    "    \n",
    "    # line 17 is SQLite syntax, the \"?,?,?,?,?\" part is needed to fill the 5 different columns\n",
    "    c.execute(\"INSERT INTO cars (vehicle, unix, hours, date, value) VALUES (?, ?, ?, ?, ?)\",\n",
    "              # line 18 gets the variables out of the parameters of the function to put into the tabel\n",
    "             (vehicle, unix, hours, date, value))\n",
    "    \n",
    "    # commit to the database defined on line 38 of previous cell\n",
    "    conn.commit()\n",
    "\n",
    "def van(date, hours, value, unix):\n",
    "    vehicle = 'Van'\n",
    "    c.execute(\"INSERT INTO vans (vehicle, unix, hours, date, value) VALUES (?, ?, ?, ?, ?)\",\n",
    "             (vehicle, unix, hours, date, value))\n",
    "    conn.commit()\n",
    "    \n",
    "def HGV(date, hours, value, unix):\n",
    "    vehicle = 'HGV'\n",
    "    c.execute(\"INSERT INTO HGVs (vehicle, unix, hours, date, value) VALUES (?, ?, ?, ?, ?)\",\n",
    "             (vehicle, unix, hours, date, value))\n",
    "    conn.commit()    \n",
    "\n",
    "def bike(date, hours, value, unix):\n",
    "    vehicle = 'Bike'\n",
    "    c.execute(\"INSERT INTO bikes (vehicle, unix, hours, date, value) VALUES (?, ?, ?, ?, ?)\",\n",
    "             (vehicle, unix, hours, date, value))\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "# define check function with parameters: \n",
    "# frame width, dot location (central point of each result), size, and label\n",
    "def check(fWidth, dLoc, size, label):\n",
    "    # get unix time\n",
    "    unix = time.time() \n",
    "    \n",
    "    # create date from unix time\n",
    "    date = str(datetime.datetime.fromtimestamp(unix).strftime('%Y-%m-%d')) \n",
    "    \n",
    "    # create time from unix time\n",
    "    hours = str(datetime.datetime.fromtimestamp(unix).strftime('%H:%M:%S')) \n",
    "    \n",
    "    # value of entry\n",
    "    value = 1\n",
    "    \n",
    "    # defines the central point of the screen\n",
    "    center = fWidth//2\n",
    "    \n",
    "    # check if the location of the dot is inside this central area \n",
    "    # (size comes from line 6 of the cell below)\n",
    "    if dLoc < center+size and dLoc > center-size:\n",
    "        \n",
    "        # checks the label assigned to each region of interest\n",
    "        # depending on the label, run the corresponding function above\n",
    "        # print confirmation of data going into the database\n",
    "        if label == \"car\":                        \n",
    "            car(date, hours, value, unix)         \n",
    "            print(\"Adding to cars...\")            \n",
    "            \n",
    "        elif label == \"van\":\n",
    "            van(date, hours, value, unix)\n",
    "            print(\"Adding to vans...\")\n",
    "\n",
    "        elif label == \"HGV\":\n",
    "            HGV(date, hours, value, unix)\n",
    "            print(\"Adding to HGVs...\")\n",
    "\n",
    "        elif label == \"motor bike\":\n",
    "            bike(date, hours, value, unix)\n",
    "            print(\"Adding to bikes...\")\n",
    "\n",
    "    return\n",
    "\n",
    "# display function, this is where the magic happens!!\n",
    "# parameters are: results, which come from YOLO,\n",
    "# the image (webcam feed), width and height of the frame,\n",
    "# the check function, and the size variable\n",
    "def display(results, img, width, height, check, size):\n",
    "    \n",
    "    # draw lines around the central area (so you can see it on screen)\n",
    "    cv2.line(img, ((width//2)+size, 0), ((height//2)+size, height),(0, 0, 0), 1)\n",
    "    cv2.line(img, ((width//2)-size, 0), ((height//2)-size, height),(0, 0, 0), 1)\n",
    "\n",
    "    # loops through each result, returned by the YOLO object detector\n",
    "    # pulls the X and Y coordinate of the top left point, \n",
    "    # and stores them in appropriate variables\n",
    "    # use the X and Y point of the bottom right location to\n",
    "    # work out the width and height of each box\n",
    "    # (look inside darkflow/net/flow.py to find the code which returns each result)\n",
    "    for (i, result) in enumerate(results):\n",
    "        x = result['topleft']['x']\n",
    "        y = result['topleft']['y']\n",
    "        w = result['bottomright']['x']-result['topleft']['x']\n",
    "        h = result['bottomright']['y']-result['topleft']['y']\n",
    "        \n",
    "        # work out central point of each result\n",
    "        w2 = (x+w//2)\n",
    "        h2 = (y+h//2)\n",
    "        \n",
    "        # each result has a label assigned to it, these labels are what i named each class while\n",
    "        # labelling my data set (car, van, HGV, and motor bike)\n",
    "        # look at the \"process_box\" function, inside: darkflow/darkflow/net/yolo/predict.py \n",
    "        # to see how YOLO assigns the label. I believe its from the meta data which comes\n",
    "        # from the XML files which i created when labelling the dataset.\n",
    "        # lines 100 - 118 check the label returned by YOLO...\n",
    "        # draw a rectangle around each result\n",
    "        # put a small dot in the center of each result\n",
    "        # run the check function (to see if the center of the box is in the center of the screen,\n",
    "        # if it is, add one to the appropriate table)\n",
    "        if result['label'] == str('car'):\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "            cv2.circle(img, (w2, h2), 2, (0,255,0), 1)\n",
    "            check(width, w2, size, str('car'))\n",
    "            \n",
    "        elif result['label'] == str('van'):\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "            cv2.circle(img, (w2, h2), 2, (255,0,0), 1)\n",
    "            check(width, w2, size, str('van'))\n",
    "            \n",
    "        elif result['label'] == str('HGV'):\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "            cv2.circle(img, (w2, h2), 2, (0,0,255), 1)\n",
    "            check(width, w2, size, str('HGV'))\n",
    "            \n",
    "        elif result['label'] == str('motor bike'):\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),1)\n",
    "            cv2.circle(img, (w2, h2), 2, (255,255,0), 1)\n",
    "            check(width, w2, size, str('motor bike'))\n",
    "            \n",
    "        # variable used to position the label of each result\n",
    "        label_position = (x + int(w/2)), abs(y - 10)\n",
    "\n",
    "        # lines 133 to 137 puts text above each result, add the label of the result, followed by a space, \n",
    "        # followed by the confidence of the prediction restricted to 4 charachters (for example: 0.76)\n",
    "        # (each result could have over 10 decimal points, varible \"d\" is to keep it tidy)\n",
    "        a = result['label']\n",
    "        b = str('__')\n",
    "        c = str(result['confidence'])\n",
    "        d = c[0:4]\n",
    "        cv2.putText(img, a + b + d, label_position , cv2.FONT_HERSHEY_SIMPLEX,0.5, (255,255,255), 1)\n",
    "        \n",
    "        \n",
    "        # bear in mind that lines 101 - 150 are in a loop, running over every result\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the width and height of the frame\n",
    "F_W = 1024    \n",
    "F_H = 1024\n",
    "\n",
    "# size variable is passed throught he display function, into the check function\n",
    "size = 12     \n",
    "\n",
    "# lines 10 to 13 are OpenCV functions. In order they open the webcam feed, set the \n",
    "# width and height of the frame, and deactivate the autofocus\n",
    "capture = cv2.VideoCapture(0)   \n",
    "capture.set(3, F_W)\n",
    "capture.set(4, F_H)\n",
    "capture.set(cv2.CAP_PROP_AUTOFOCUS, 0)\n",
    "\n",
    "# run create table function from line 4, of cell 2 (incase the tables do not exist)\n",
    "create_table()\n",
    "\n",
    "# infinately assign the webcam feed to the frame variable\n",
    "while True: \n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    # ret obtains a return value from getting the camera frame, either true of false\n",
    "    if ret:\n",
    "        \n",
    "        # webcam feed is passed into the YOLO algorithm, stored in the results variable\n",
    "        results = tfnet.return_predict(frame)\n",
    "        \n",
    "        # results variable is passed into the display function, from line 76 of the above cell\n",
    "        image = display(results, frame, F_W, F_H, check, size)\n",
    "        \n",
    "        # display the webcam feed in a new window, with boxes, labels, and confidence scores around each\n",
    "        # result\n",
    "        cv2.imshow('TMAS - Creative Project', image)\n",
    "        \n",
    "        # press enter to break the loop, and execute code on lines 41-44\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "            \n",
    "# close all connections (SQLite database connection, and OpenCV webcam connection)\n",
    "c.close()\n",
    "conn.close()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to close all connections (if the program crashes)\n",
    "# then restart the program\n",
    "c.close()\n",
    "conn.close()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
